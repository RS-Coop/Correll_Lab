<%BEGIN_DEFINITION_TEMPLATE>
/********************
    dense.cpp

    Code generated using nn4mc.

    This file implements a densely connected layer.

*/

#include "dense.h"
#include "activations.h"
#include <math.h>
#include <stdlib.h>

#define max(a, b) (((a)>(b) ? (a) : (b)))
#define min(a, b) (((a)<(b) ? (a) : (b)))


struct Dense buildDense(<%WEIGHT_DATATYPE_DELIMITER>* W, <%WEIGHT_DATATYPE_DELIMITER>* b, <%INDEX_DATATYPE_DELIMITER> input_size, <%INDEX_DATATYPE_DELIMITER> output_size, <%ACTIVATION_DATATYPE_DELIMITER> activation, bool use_bias)
{
	struct Dense layer;

	layer.weights = W;
	layer.biases = b;
	
	layer.input_shape[0] = input_size;
	layer.output_shape[0] = output_size;
    layer.weight_shape[0] = input_size;
    layer.weight_shape[1] = output_size;
    layer.activation = activation;
    layer.use_bias = use_bias;
	return layer;
}


<%LAYER_DATATYPE_DELIMITER> * fwdDense(struct Dense L, <%LAYER_DATATYPE_DELIMITER>* input)
{

    <%LAYER_DATATYPE_DELIMITER> * h = (<%LAYER_DATATYPE_DELIMITER>*)malloc(L.output_shape[0] * sizeof(<%LAYER_DATATYPE_DELIMITER>));

	// Loop through to calculate the output at each point
	for(<%INDEX_DATATYPE_DELIMITER> i = 0; i < L.output_shape[0]; i++)
	{
		if (L.use_bias){
			h[i] = L.biases[i];
		} else{
			h[i] = 0.0;
		}

		for(<%INDEX_DATATYPE_DELIMITER> j = 0; j < L.input_shape[0]; j++)
		{
            		h[i] += *(L.weights + j*L.weight_shape[1] + i)*input[j];
		}

		if(L.activation != 0xB)
			h[i] = activate(h[i],L.output_shape[0],L.activation);
	}

    free(input);
    return h;

}
<%END_DEFINITION_TEMPLATE>


<%BEGIN_INITIALIZE_TEMPLATE>
        <%LAYER_NAME> = buildDense(&<%WEIGHT_NAME>[0], <%BIAS_NAME>, <%INPUT_SHAPE_0>, <%OUTPUT_SIZE>, <%ACTIVATION>, <%USE_BIAS>);
<%END_INITIALIZE_TEMPLATE>

<%BEGIN_CALL_TEMPLATE>
        data = fwdDense(<%LAYER_NAME>, <%INPUT>);
<%END_CALL_TEMPLATE>
